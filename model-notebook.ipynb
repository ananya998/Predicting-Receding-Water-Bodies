{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR0utp8tVyvK"
      },
      "source": [
        "Features:\n",
        "\n",
        "- Days\n",
        "\n",
        "- Rainfall indicates the quantity of rain falling (mm)\n",
        "\n",
        "- Temperature indicates the temperature (°C)\n",
        "\n",
        "- Volume indicates the volume of water taken from the drinking water treatment plant (m**3)\n",
        "\n",
        "- Hydrometry indicates the groundwater level (m)\n",
        "\n",
        "Target:\n",
        "\n",
        "- Depth to Groundwater indicates the groundwater level (m from the ground floor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qZr-xQ7YBsM"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\\\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y3lJVZufUMm4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "from sklearn.preprocessing import RobustScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir5Ug_X8YB5R"
      },
      "source": [
        "Days (0-365)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X9cWrfTWD4L",
        "outputId": "56f0ad15-2115-47fa-bf70-e4c1f19642a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 45,\n",
              " 46,\n",
              " 47,\n",
              " 48,\n",
              " 49,\n",
              " 50,\n",
              " 51,\n",
              " 52,\n",
              " 53,\n",
              " 54,\n",
              " 55,\n",
              " 56,\n",
              " 57,\n",
              " 58,\n",
              " 59,\n",
              " 60,\n",
              " 61,\n",
              " 62,\n",
              " 63,\n",
              " 64,\n",
              " 65,\n",
              " 66,\n",
              " 67,\n",
              " 68,\n",
              " 69,\n",
              " 70,\n",
              " 71,\n",
              " 72,\n",
              " 73,\n",
              " 74,\n",
              " 75,\n",
              " 76,\n",
              " 77,\n",
              " 78,\n",
              " 79,\n",
              " 80,\n",
              " 81,\n",
              " 82,\n",
              " 83,\n",
              " 84,\n",
              " 85,\n",
              " 86,\n",
              " 87,\n",
              " 88,\n",
              " 89,\n",
              " 90,\n",
              " 91,\n",
              " 92,\n",
              " 93,\n",
              " 94,\n",
              " 95,\n",
              " 96,\n",
              " 97,\n",
              " 98,\n",
              " 99,\n",
              " 100,\n",
              " 101,\n",
              " 102,\n",
              " 103,\n",
              " 104,\n",
              " 105,\n",
              " 106,\n",
              " 107,\n",
              " 108,\n",
              " 109,\n",
              " 110,\n",
              " 111,\n",
              " 112,\n",
              " 113,\n",
              " 114,\n",
              " 115,\n",
              " 116,\n",
              " 117,\n",
              " 118,\n",
              " 119,\n",
              " 120,\n",
              " 121,\n",
              " 122,\n",
              " 123,\n",
              " 124,\n",
              " 125,\n",
              " 126,\n",
              " 127,\n",
              " 128,\n",
              " 129,\n",
              " 130,\n",
              " 131,\n",
              " 132,\n",
              " 133,\n",
              " 134,\n",
              " 135,\n",
              " 136,\n",
              " 137,\n",
              " 138,\n",
              " 139,\n",
              " 140,\n",
              " 141,\n",
              " 142,\n",
              " 143,\n",
              " 144,\n",
              " 145,\n",
              " 146,\n",
              " 147,\n",
              " 148,\n",
              " 149,\n",
              " 150,\n",
              " 151,\n",
              " 152,\n",
              " 153,\n",
              " 154,\n",
              " 155,\n",
              " 156,\n",
              " 157,\n",
              " 158,\n",
              " 159,\n",
              " 160,\n",
              " 161,\n",
              " 162,\n",
              " 163,\n",
              " 164,\n",
              " 165,\n",
              " 166,\n",
              " 167,\n",
              " 168,\n",
              " 169,\n",
              " 170,\n",
              " 171,\n",
              " 172,\n",
              " 173,\n",
              " 174,\n",
              " 175,\n",
              " 176,\n",
              " 177,\n",
              " 178,\n",
              " 179,\n",
              " 180,\n",
              " 181,\n",
              " 182,\n",
              " 183,\n",
              " 184,\n",
              " 185,\n",
              " 186,\n",
              " 187,\n",
              " 188,\n",
              " 189,\n",
              " 190,\n",
              " 191,\n",
              " 192,\n",
              " 193,\n",
              " 194,\n",
              " 195,\n",
              " 196,\n",
              " 197,\n",
              " 198,\n",
              " 199,\n",
              " 200,\n",
              " 201,\n",
              " 202,\n",
              " 203,\n",
              " 204,\n",
              " 205,\n",
              " 206,\n",
              " 207,\n",
              " 208,\n",
              " 209,\n",
              " 210,\n",
              " 211,\n",
              " 212,\n",
              " 213,\n",
              " 214,\n",
              " 215,\n",
              " 216,\n",
              " 217,\n",
              " 218,\n",
              " 219,\n",
              " 220,\n",
              " 221,\n",
              " 222,\n",
              " 223,\n",
              " 224,\n",
              " 225,\n",
              " 226,\n",
              " 227,\n",
              " 228,\n",
              " 229,\n",
              " 230,\n",
              " 231,\n",
              " 232,\n",
              " 233,\n",
              " 234,\n",
              " 235,\n",
              " 236,\n",
              " 237,\n",
              " 238,\n",
              " 239,\n",
              " 240,\n",
              " 241,\n",
              " 242,\n",
              " 243,\n",
              " 244,\n",
              " 245,\n",
              " 246,\n",
              " 247,\n",
              " 248,\n",
              " 249,\n",
              " 250,\n",
              " 251,\n",
              " 252,\n",
              " 253,\n",
              " 254,\n",
              " 255,\n",
              " 256,\n",
              " 257,\n",
              " 258,\n",
              " 259,\n",
              " 260,\n",
              " 261,\n",
              " 262,\n",
              " 263,\n",
              " 264,\n",
              " 265,\n",
              " 266,\n",
              " 267,\n",
              " 268,\n",
              " 269,\n",
              " 270,\n",
              " 271,\n",
              " 272,\n",
              " 273,\n",
              " 274,\n",
              " 275,\n",
              " 276,\n",
              " 277,\n",
              " 278,\n",
              " 279,\n",
              " 280,\n",
              " 281,\n",
              " 282,\n",
              " 283,\n",
              " 284,\n",
              " 285,\n",
              " 286,\n",
              " 287,\n",
              " 288,\n",
              " 289,\n",
              " 290,\n",
              " 291,\n",
              " 292,\n",
              " 293,\n",
              " 294,\n",
              " 295,\n",
              " 296,\n",
              " 297,\n",
              " 298,\n",
              " 299,\n",
              " 300,\n",
              " 301,\n",
              " 302,\n",
              " 303,\n",
              " 304,\n",
              " 305,\n",
              " 306,\n",
              " 307,\n",
              " 308,\n",
              " 309,\n",
              " 310,\n",
              " 311,\n",
              " 312,\n",
              " 313,\n",
              " 314,\n",
              " 315,\n",
              " 316,\n",
              " 317,\n",
              " 318,\n",
              " 319,\n",
              " 320,\n",
              " 321,\n",
              " 322,\n",
              " 323,\n",
              " 324,\n",
              " 325,\n",
              " 326,\n",
              " 327,\n",
              " 328,\n",
              " 329,\n",
              " 330,\n",
              " 331,\n",
              " 332,\n",
              " 333,\n",
              " 334,\n",
              " 335,\n",
              " 336,\n",
              " 337,\n",
              " 338,\n",
              " 339,\n",
              " 340,\n",
              " 341,\n",
              " 342,\n",
              " 343,\n",
              " 344,\n",
              " 345,\n",
              " 346,\n",
              " 347,\n",
              " 348,\n",
              " 349,\n",
              " 350,\n",
              " 351,\n",
              " 352,\n",
              " 353,\n",
              " 354,\n",
              " 355,\n",
              " 356,\n",
              " 357,\n",
              " 358,\n",
              " 359,\n",
              " 360,\n",
              " 361,\n",
              " 362,\n",
              " 363,\n",
              " 364,\n",
              " 365]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "days = []\n",
        "for i in range(1,366,1):\n",
        "  days.append(i)\n",
        "days"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqWbcWBlaFDS"
      },
      "source": [
        "Depth Ground Water (30-32m Max limit of changes in depth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RLL_cwWqZW0B"
      },
      "outputs": [],
      "source": [
        "from random import uniform\n",
        "\n",
        "x = 1\n",
        "depth = []\n",
        "while x!=366:\n",
        "    depth.append(round(uniform(30, 32), 2)) # water level randomised between 30 & 40 m\n",
        "    x+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVzrNCmuJWmk"
      },
      "source": [
        "Rain (India average: 400 - 500 mm) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WOGWO4zkJUsi"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "x = 1\n",
        "rain = []\n",
        "while x!=366:\n",
        "    rain.append(round(uniform(400, 500), 2)) \n",
        "    x+=1\n",
        "\n",
        "for x in range(200): # Putting Zeroes in rain as everyday no rainfall\n",
        "    i = random.randint(0,365)\n",
        "    rain[i] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BmUViuqf5Bp",
        "outputId": "c02f5fb7-c825-43ae-c416-ac55e6d57500"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "152"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Number of zeroes in rain\n",
        "\n",
        "x = 0\n",
        "c = 0\n",
        "while x < 365:\n",
        "  if rain[x] == 0:\n",
        "      c = c+1\n",
        "  x = x+1\n",
        "c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQBljoUTJh-g"
      },
      "source": [
        "Temperature (15 - 25 degree celsius)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BIOXoC7mJuBX"
      },
      "outputs": [],
      "source": [
        "x = 1\n",
        "temp = []\n",
        "while x!=366:\n",
        "    temp.append(round(uniform(16, 25), 2)) \n",
        "    x+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5cI3K-vJuQR"
      },
      "source": [
        "Hydrometry / Groundwater Level (15-20) ***(Target)***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z7uhC7oYJ3xe"
      },
      "outputs": [],
      "source": [
        "x = 1\n",
        "level = []\n",
        "while x!=366:\n",
        "    level.append(round(uniform(15, 20), 2)) \n",
        "    x+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U03yoQtiPTYB"
      },
      "source": [
        "Joining Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "IpDK-luHPWG7",
        "outputId": "f5023275-9c34-4449-9ede-613ace79e327"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>depth</th>\n",
              "      <th>rain</th>\n",
              "      <th>temp</th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30.23</td>\n",
              "      <td>433.13</td>\n",
              "      <td>21.04</td>\n",
              "      <td>17.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31.83</td>\n",
              "      <td>416.98</td>\n",
              "      <td>24.86</td>\n",
              "      <td>17.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30.29</td>\n",
              "      <td>494.76</td>\n",
              "      <td>19.38</td>\n",
              "      <td>15.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.24</td>\n",
              "      <td>472.95</td>\n",
              "      <td>21.06</td>\n",
              "      <td>17.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31.28</td>\n",
              "      <td>0.00</td>\n",
              "      <td>24.33</td>\n",
              "      <td>16.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>30.46</td>\n",
              "      <td>407.80</td>\n",
              "      <td>18.04</td>\n",
              "      <td>17.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>31.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>16.83</td>\n",
              "      <td>16.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>31.51</td>\n",
              "      <td>497.96</td>\n",
              "      <td>23.79</td>\n",
              "      <td>19.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>30.79</td>\n",
              "      <td>0.00</td>\n",
              "      <td>24.22</td>\n",
              "      <td>16.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>31.46</td>\n",
              "      <td>497.39</td>\n",
              "      <td>20.22</td>\n",
              "      <td>19.36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>365 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     depth    rain   temp  level\n",
              "0    30.23  433.13  21.04  17.68\n",
              "1    31.83  416.98  24.86  17.12\n",
              "2    30.29  494.76  19.38  15.64\n",
              "3    31.24  472.95  21.06  17.89\n",
              "4    31.28    0.00  24.33  16.40\n",
              "..     ...     ...    ...    ...\n",
              "360  30.46  407.80  18.04  17.73\n",
              "361  31.12    0.00  16.83  16.89\n",
              "362  31.51  497.96  23.79  19.26\n",
              "363  30.79    0.00  24.22  16.56\n",
              "364  31.46  497.39  20.22  19.36\n",
              "\n",
              "[365 rows x 4 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arr = [days, depth, rain, temp, level] # put all columns in array and convert to dataframe.\n",
        "arr = pd.DataFrame(arr) # convert\n",
        "arr = arr.T # Transposing/Rotating by 90 degree\n",
        "arr.columns = ['days', 'depth', 'rain', 'temp', 'level']\n",
        "arr = arr.drop(['days'], axis = 1) # Days not reqd. Index is sufficient\n",
        "arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF45ffSpXSjE"
      },
      "source": [
        "Features Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VUP-DWTFW9pi"
      },
      "outputs": [],
      "source": [
        "X = arr.iloc[:,0:-1] # [row1:row2, column1:column2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9v8hEH-XWNA"
      },
      "source": [
        "Target Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "j7ne2lRJXULI"
      },
      "outputs": [],
      "source": [
        "Y = arr['level']\n",
        "# arr.to_csv('data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQke6YQ2wyTA"
      },
      "source": [
        "# LSTM 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "isTPUTmz0fNp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y,shuffle=False, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhHFWx3Fm0_e",
        "outputId": "88b42110-501f-4ac6-cab1-4d7635503c4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "9/9 [==============================] - 2s 7ms/step - loss: 352.2766\n",
            "Epoch 2/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 275.7045\n",
            "Epoch 3/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 146.8061\n",
            "Epoch 4/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 104.0542\n",
            "Epoch 5/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 64.0290\n",
            "Epoch 6/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.7077\n",
            "Epoch 7/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.4171\n",
            "Epoch 8/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1187\n",
            "Epoch 9/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6249\n",
            "Epoch 10/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5540\n",
            "Epoch 11/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4044\n",
            "Epoch 12/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4206\n",
            "Epoch 13/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3295\n",
            "Epoch 14/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2850\n",
            "Epoch 15/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2080\n",
            "Epoch 16/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2051\n",
            "Epoch 17/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2112\n",
            "Epoch 18/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2255\n",
            "Epoch 19/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3229\n",
            "Epoch 20/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1907\n",
            "Epoch 21/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2049\n",
            "Epoch 22/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1404\n",
            "Epoch 23/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1273\n",
            "Epoch 24/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3442\n",
            "Epoch 25/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2359\n",
            "Epoch 26/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1987\n",
            "Epoch 27/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1646\n",
            "Epoch 28/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2404\n",
            "Epoch 29/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2397\n",
            "Epoch 30/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3135\n",
            "Epoch 31/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6092\n",
            "Epoch 32/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1480\n",
            "Epoch 33/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1629\n",
            "Epoch 34/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2506\n",
            "Epoch 35/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3970\n",
            "Epoch 36/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2070\n",
            "Epoch 37/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2078\n",
            "Epoch 38/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2128\n",
            "Epoch 39/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2826\n",
            "Epoch 40/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1398\n",
            "Epoch 41/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2069\n",
            "Epoch 42/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.3851\n",
            "Epoch 43/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2529\n",
            "Epoch 44/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2779\n",
            "Epoch 45/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1766\n",
            "Epoch 46/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3439\n",
            "Epoch 47/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.3354\n",
            "Epoch 48/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1191\n",
            "Epoch 49/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1594\n",
            "Epoch 50/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3008\n",
            "Epoch 51/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1687\n",
            "Epoch 52/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1719\n",
            "Epoch 53/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2361\n",
            "Epoch 54/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3087\n",
            "Epoch 55/200\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.0975\n",
            "Epoch 56/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1640\n",
            "Epoch 57/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.0796\n",
            "Epoch 58/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2431\n",
            "Epoch 59/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1574\n",
            "Epoch 60/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1194\n",
            "Epoch 61/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1208\n",
            "Epoch 62/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2191\n",
            "Epoch 63/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2031\n",
            "Epoch 64/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2047\n",
            "Epoch 65/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1812\n",
            "Epoch 66/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.0902\n",
            "Epoch 67/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1132\n",
            "Epoch 68/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2497\n",
            "Epoch 69/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2714\n",
            "Epoch 70/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2572\n",
            "Epoch 71/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2070\n",
            "Epoch 72/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3602\n",
            "Epoch 73/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1290\n",
            "Epoch 74/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2068\n",
            "Epoch 75/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1734\n",
            "Epoch 76/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1804\n",
            "Epoch 77/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5711\n",
            "Epoch 78/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4266\n",
            "Epoch 79/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.3175\n",
            "Epoch 80/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.2407\n",
            "Epoch 81/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1875\n",
            "Epoch 82/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1451\n",
            "Epoch 83/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1246\n",
            "Epoch 84/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1501\n",
            "Epoch 85/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1528\n",
            "Epoch 86/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0740\n",
            "Epoch 87/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1620\n",
            "Epoch 88/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1967\n",
            "Epoch 89/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1273\n",
            "Epoch 90/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1778\n",
            "Epoch 91/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1406\n",
            "Epoch 92/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.0989\n",
            "Epoch 93/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.0763\n",
            "Epoch 94/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1754\n",
            "Epoch 95/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1317\n",
            "Epoch 96/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1474\n",
            "Epoch 97/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0620\n",
            "Epoch 98/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4612\n",
            "Epoch 99/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2846\n",
            "Epoch 100/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.2942\n",
            "Epoch 101/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3372\n",
            "Epoch 102/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3263\n",
            "Epoch 103/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1747\n",
            "Epoch 104/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2841\n",
            "Epoch 105/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3985\n",
            "Epoch 106/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.5172\n",
            "Epoch 107/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3246\n",
            "Epoch 108/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.2406\n",
            "Epoch 109/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1924\n",
            "Epoch 110/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3923\n",
            "Epoch 111/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2504\n",
            "Epoch 112/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1892\n",
            "Epoch 113/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.2921\n",
            "Epoch 114/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.3329\n",
            "Epoch 115/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4743\n",
            "Epoch 116/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1672\n",
            "Epoch 117/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1353\n",
            "Epoch 118/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1059\n",
            "Epoch 119/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1243\n",
            "Epoch 120/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.0455\n",
            "Epoch 121/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1495\n",
            "Epoch 122/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0980\n",
            "Epoch 123/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0784\n",
            "Epoch 124/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1250\n",
            "Epoch 125/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4146\n",
            "Epoch 126/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.5613\n",
            "Epoch 127/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6227\n",
            "Epoch 128/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5275\n",
            "Epoch 129/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2602\n",
            "Epoch 130/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1937\n",
            "Epoch 131/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1307\n",
            "Epoch 132/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.0990\n",
            "Epoch 133/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.2157\n",
            "Epoch 134/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0896\n",
            "Epoch 135/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0921\n",
            "Epoch 136/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2172\n",
            "Epoch 137/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3275\n",
            "Epoch 138/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1468\n",
            "Epoch 139/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0728\n",
            "Epoch 140/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1999\n",
            "Epoch 141/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1504\n",
            "Epoch 142/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4086\n",
            "Epoch 143/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4030\n",
            "Epoch 144/200\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.1372\n",
            "Epoch 145/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1456\n",
            "Epoch 146/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0713\n",
            "Epoch 147/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1593\n",
            "Epoch 148/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1064\n",
            "Epoch 149/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.2722\n",
            "Epoch 150/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4164\n",
            "Epoch 151/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1225\n",
            "Epoch 152/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0666\n",
            "Epoch 153/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1003\n",
            "Epoch 154/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4767\n",
            "Epoch 155/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4414\n",
            "Epoch 156/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4103\n",
            "Epoch 157/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1435\n",
            "Epoch 158/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0765\n",
            "Epoch 159/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.2224\n",
            "Epoch 160/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0544\n",
            "Epoch 161/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2094\n",
            "Epoch 162/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1739\n",
            "Epoch 163/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1348\n",
            "Epoch 164/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1950\n",
            "Epoch 165/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1319\n",
            "Epoch 166/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1669\n",
            "Epoch 167/200\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.1713\n",
            "Epoch 168/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.2975\n",
            "Epoch 169/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1384\n",
            "Epoch 170/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4223\n",
            "Epoch 171/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6227\n",
            "Epoch 172/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3149\n",
            "Epoch 173/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.2206\n",
            "Epoch 174/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.0812\n",
            "Epoch 175/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1433\n",
            "Epoch 176/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1928\n",
            "Epoch 177/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1762\n",
            "Epoch 178/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0963\n",
            "Epoch 179/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2144\n",
            "Epoch 180/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3369\n",
            "Epoch 181/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.3155\n",
            "Epoch 182/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2885\n",
            "Epoch 183/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3371\n",
            "Epoch 184/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3293\n",
            "Epoch 185/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2520\n",
            "Epoch 186/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.0041\n",
            "Epoch 187/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1916\n",
            "Epoch 188/200\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0859\n",
            "Epoch 189/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3389\n",
            "Epoch 190/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2371\n",
            "Epoch 191/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3075\n",
            "Epoch 192/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0491\n",
            "Epoch 193/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0864\n",
            "Epoch 194/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1083\n",
            "Epoch 195/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0868\n",
            "Epoch 196/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1088\n",
            "Epoch 197/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2401\n",
            "Epoch 198/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1038\n",
            "Epoch 199/200\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1584\n",
            "Epoch 200/200\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2595\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f54db6a3a50>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        " \n",
        "# split a univariate sequence\n",
        "def split_sequence(sequence, n_steps):\n",
        "\tX, y = list(), list()\n",
        "\tfor i in range(len(sequence)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(sequence)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn array(X), array(y)\n",
        " \n",
        "# define input sequence\n",
        "#raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# split into samples\n",
        "#X, y = split_sequence(raw_seq, n_steps)\n",
        "\n",
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "#X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(X_train, y_train, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "768F3hSrlWG1",
        "outputId": "a485c6cc-bdf4-4036-cec8-a475562216c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[18.078762]\n",
            " [18.378275]\n",
            " [18.169128]\n",
            " [18.384935]\n",
            " [18.191893]\n",
            " [17.80762 ]\n",
            " [18.38994 ]\n",
            " [18.06505 ]\n",
            " [17.884626]\n",
            " [18.016039]]\n"
          ]
        }
      ],
      "source": [
        "# demonstrate prediction\n",
        "n = 10\n",
        "x_input = array(X_test[0:n])\n",
        "x_input = x_input.reshape((n, n_steps, n_features))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHJln3HP3DVt",
        "outputId": "2b457b48-4dc2-43db-e02a-fe4ec2e9a97b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "273    18.89\n",
            "274    16.82\n",
            "275    15.67\n",
            "276    19.68\n",
            "277    15.88\n",
            "278    18.10\n",
            "279    19.84\n",
            "280    18.37\n",
            "281    15.88\n",
            "282    18.14\n",
            "Name: level, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "y_actual = y_test[0:n]\n",
        "print(y_actual)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFmjHhAQzUiH"
      },
      "source": [
        "The input to every LSTM layer must be three-dimensional.\n",
        "\n",
        "The three dimensions of this input are:\n",
        "\n",
        "- **Samples:** One sequence is one sample. A batch is comprised of one or more samples.\n",
        "\n",
        "- **Time Steps:** One time step is one point of observation in the sample.\n",
        "\n",
        "- **Features:** One feature is one observation at a time step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uccBu926I8K5"
      },
      "source": [
        "[samples, timesteps, features]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Receding Water Bodies.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
